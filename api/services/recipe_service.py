#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ¬ã‚·ãƒ”ã‚µãƒ¼ãƒ“ã‚¹ - ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ç®¡ç†ã‚’æ‹…å½“
æ—¢å­˜ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã®çµ±åˆã€æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½

Author: Recipe-DevUI Agent
Date: 2025-08-08
"""

import json
import asyncio
from pathlib import Path
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta, timezone
import logging

from models.recipe_models import (
    Recipe, RecipeFilters, ChannelStats, ChannelType, 
    DashboardSummary, VideoData, DifficultyLevel
)

logger = logging.getLogger(__name__)

class RecipeService:
    """ãƒ¬ã‚·ãƒ”ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self, data_dir: Optional[Path] = None):
        """åˆæœŸåŒ–"""
        self.data_dir = data_dir or Path("../data")
        self.data_dir.mkdir(exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        self.processed_videos_file = self.data_dir / "processed_videos.json"
        self.failed_videos_file = self.data_dir / "failed_videos.json"
        self.metrics_file = self.data_dir / "metrics.json"
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._recipe_cache: List[Recipe] = []
        self._cache_last_updated: Optional[datetime] = None
        self._cache_ttl = timedelta(minutes=5)
        
        logger.info(f"ğŸ³ RecipeService initialized with data_dir: {self.data_dir}")
    
    async def _load_recipes_from_file(self) -> List[Recipe]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¬ã‚·ãƒ”ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            if not self.processed_videos_file.exists():
                logger.warning("processed_videos.json not found, returning empty list")
                return []
            
            with open(self.processed_videos_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            recipes = []
            for video_id, video_data in data.items():
                try:
                    recipe = self._convert_to_recipe_model(video_id, video_data)
                    if recipe:
                        recipes.append(recipe)
                except Exception as e:
                    logger.error(f"Error converting video {video_id} to recipe: {e}")
            
            logger.info(f"ğŸ“š Loaded {len(recipes)} recipes from file")
            return recipes
            
        except Exception as e:
            logger.error(f"Error loading recipes from file: {e}")
            return []
    
    def _convert_to_recipe_model(self, video_id: str, video_data: Dict[str, Any]) -> Optional[Recipe]:
        """JSONãƒ‡ãƒ¼ã‚¿ã‚’Recipeãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›"""
        try:
            # VideoDataä½œæˆ
            video = VideoData(
                video_id=video_id,
                title=video_data.get('title', ''),
                description=video_data.get('description', ''),
                channel_id=video_data.get('channel_id', ''),
                channel_name=video_data.get('channel_name', ''),
                published_at=datetime.fromisoformat(
                    video_data.get('published_at', datetime.now(timezone.utc).isoformat())
                ),
                duration=video_data.get('duration', 'PT0S'),
                thumbnail_url=video_data.get('thumbnail_url', ''),
                view_count=video_data.get('view_count', 0),
                like_count=video_data.get('like_count', 0),
                url=video_data.get('youtube_url', f'https://www.youtube.com/watch?v={video_id}')
            )
            
            # ãƒãƒ£ãƒ³ãƒãƒ«ç¨®åˆ¥ã‚’åˆ¤å®š
            channel_map = {
                'UC8C7QblJwCHsYrftuLjGKig': ChannelType.SAM_COOKING,
                'UCJFp8uSYCjXOMnkUyb3CQ3Q': ChannelType.TASTY,
                'UChBEbMKI1eCcejTtmI32UEw': ChannelType.JOSHUA
            }
            channel = channel_map.get(video.channel_id, ChannelType.SAM_COOKING)
            
            # Recipeä½œæˆ
            recipe = Recipe(
                recipe_id=video_data.get('recipe_id', video_id),
                source_video=video,
                title_ja=video_data.get('title_ja', video_data.get('title', '')),
                description_ja=video_data.get('description_ja', video_data.get('description', '')),
                ingredients=video_data.get('ingredients', ['ææ–™æƒ…å ±ã‚’è§£æä¸­...']),
                instructions=video_data.get('instructions', ['æ‰‹é †æƒ…å ±ã‚’è§£æä¸­...']),
                cooking_time=video_data.get('cooking_time'),
                difficulty=DifficultyLevel(video_data.get('difficulty', 3)),
                tags=video_data.get('tags', []),
                category=video_data.get('category', 'è‚‰æ–™ç†'),
                quality_score=video_data.get('quality_score', 0.8),
                processed_at=datetime.fromisoformat(
                    video_data.get('processed_at', datetime.now(timezone.utc).isoformat())
                ),
                notion_url=video_data.get('notion_url'),
                notion_page_id=video_data.get('notion_page_id'),
                channel=channel
            )
            
            return recipe
            
        except Exception as e:
            logger.error(f"Error converting video data to recipe: {e}")
            return None
    
    async def _get_cached_recipes(self) -> List[Recipe]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¬ã‚·ãƒ”ã‚’å–å¾—ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ›´æ–°ï¼‰"""
        now = datetime.now(timezone.utc)
        
        if (not self._recipe_cache or 
            not self._cache_last_updated or 
            now - self._cache_last_updated > self._cache_ttl):
            
            logger.debug("ğŸ”„ Refreshing recipe cache")
            self._recipe_cache = await self._load_recipes_from_file()
            self._cache_last_updated = now
        
        return self._recipe_cache
    
    async def get_recipes(self, filters: RecipeFilters) -> List[Recipe]:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã«åŸºã¥ã„ã¦ãƒ¬ã‚·ãƒ”ã‚’å–å¾—"""
        try:
            recipes = await self._get_cached_recipes()
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é©ç”¨
            filtered = recipes
            
            # ãƒãƒ£ãƒ³ãƒãƒ«ãƒ•ã‚£ãƒ«ã‚¿
            if filters.channel:
                filtered = [r for r in filtered if r.channel == filters.channel]
            
            # æ¤œç´¢ã‚¯ã‚¨ãƒªãƒ•ã‚£ãƒ«ã‚¿
            if filters.search_query:
                query = filters.search_query.lower()
                filtered = [
                    r for r in filtered 
                    if (query in r.title_ja.lower() or 
                        query in r.description_ja.lower() or
                        any(query in tag.lower() for tag in r.tags))
                ]
            
            # é›£æ˜“åº¦ãƒ•ã‚£ãƒ«ã‚¿
            if filters.difficulty:
                filtered = [r for r in filtered if r.difficulty == filters.difficulty]
            
            # å“è³ªã‚¹ã‚³ã‚¢ãƒ•ã‚£ãƒ«ã‚¿
            if filters.min_quality_score:
                filtered = [r for r in filtered if r.quality_score >= filters.min_quality_score]
            
            # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
            if filters.date_from:
                filtered = [r for r in filtered if r.processed_at >= filters.date_from]
            if filters.date_to:
                filtered = [r for r in filtered if r.processed_at <= filters.date_to]
            
            # ã‚¿ã‚°ãƒ•ã‚£ãƒ«ã‚¿
            if filters.tags:
                filtered = [
                    r for r in filtered 
                    if any(tag in r.tags for tag in filters.tags)
                ]
            
            # ã‚½ãƒ¼ãƒˆï¼ˆæœ€æ–°é †ï¼‰
            filtered.sort(key=lambda r: r.processed_at, reverse=True)
            
            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
            start = filters.offset
            end = start + filters.limit
            result = filtered[start:end]
            
            logger.info(f"ğŸ” Found {len(result)} recipes (filtered from {len(recipes)} total)")
            return result
            
        except Exception as e:
            logger.error(f"Error getting recipes: {e}")
            return []
    
    async def get_recipe_by_id(self, recipe_id: str) -> Optional[Recipe]:
        """ãƒ¬ã‚·ãƒ”IDã§ç‰¹å®šã®ãƒ¬ã‚·ãƒ”ã‚’å–å¾—"""
        try:
            recipes = await self._get_cached_recipes()
            
            for recipe in recipes:
                if recipe.recipe_id == recipe_id:
                    return recipe
            
            logger.warning(f"Recipe not found: {recipe_id}")
            return None
            
        except Exception as e:
            logger.error(f"Error getting recipe by ID: {e}")
            return None
    
    async def get_dashboard_summary(self) -> DashboardSummary:
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”¨ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’å–å¾—"""
        try:
            recipes = await self._get_cached_recipes()
            
            now = datetime.now(timezone.utc)
            today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
            week_start = today_start - timedelta(days=7)
            
            # åŸºæœ¬çµ±è¨ˆ
            total_recipes = len(recipes)
            today_processed = len([r for r in recipes if r.processed_at >= today_start])
            weekly_processed = len([r for r in recipes if r.processed_at >= week_start])
            
            # å“è³ªçµ±è¨ˆ
            if recipes:
                avg_quality = sum(r.quality_score for r in recipes) / len(recipes)
                high_quality_count = len([r for r in recipes if r.quality_score > 0.8])
            else:
                avg_quality = 0.0
                high_quality_count = 0
            
            # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥åˆ†å¸ƒ
            channel_distribution = {}
            for recipe in recipes:
                channel_name = recipe.source_video.channel_name
                channel_distribution[channel_name] = channel_distribution.get(channel_name, 0) + 1
            
            # æœ€è¿‘ã®ãƒ¬ã‚·ãƒ”ï¼ˆæœ€å¤§5ä»¶ï¼‰
            recent_recipes = sorted(recipes, key=lambda r: r.processed_at, reverse=True)[:5]
            
            # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆéå»7æ—¥é–“ï¼‰
            daily_trend = []
            for i in range(7):
                date = today_start - timedelta(days=i)
                next_date = date + timedelta(days=1)
                day_count = len([
                    r for r in recipes 
                    if date <= r.processed_at < next_date
                ])
                daily_trend.append({
                    "date": date.isoformat(),
                    "count": day_count
                })
            
            summary = DashboardSummary(
                total_recipes=total_recipes,
                today_processed=today_processed,
                weekly_processed=weekly_processed,
                avg_processing_time=5.2,  # TODO: å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã‚’è¨ˆç®—
                high_quality_count=high_quality_count,
                avg_quality_score=avg_quality,
                channel_distribution=channel_distribution,
                recent_recipes=recent_recipes,
                daily_trend=list(reversed(daily_trend))  # å¤ã„é †ã«ã‚½ãƒ¼ãƒˆ
            )
            
            logger.info(f"ğŸ“Š Generated dashboard summary: {total_recipes} total recipes")
            return summary
            
        except Exception as e:
            logger.error(f"Error generating dashboard summary: {e}")
            return DashboardSummary()  # ç©ºã®ã‚µãƒãƒªãƒ¼ã‚’è¿”ã™
    
    async def get_channel_statistics(self) -> List[ChannelStats]:
        """ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        try:
            recipes = await self._get_cached_recipes()
            
            # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            channels: Dict[ChannelType, List[Recipe]] = {}
            for recipe in recipes:
                if recipe.channel not in channels:
                    channels[recipe.channel] = []
                channels[recipe.channel].append(recipe)
            
            now = datetime.now(timezone.utc)
            today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
            
            stats_list = []
            
            for channel_type, channel_recipes in channels.items():
                if not channel_recipes:
                    continue
                
                # çµ±è¨ˆè¨ˆç®—
                total_recipes = len(channel_recipes)
                today_added = len([r for r in channel_recipes if r.processed_at >= today_start])
                avg_quality = sum(r.quality_score for r in channel_recipes) / total_recipes
                last_processed = max(r.processed_at for r in channel_recipes)
                
                # ãƒãƒ£ãƒ³ãƒãƒ«åå–å¾—
                channel_name = channel_recipes[0].source_video.channel_name
                
                # é€±é–“ãƒˆãƒ¬ãƒ³ãƒ‰
                weekly_trend = []
                for i in range(7):
                    date = today_start - timedelta(days=i)
                    next_date = date + timedelta(days=1)
                    day_count = len([
                        r for r in channel_recipes 
                        if date <= r.processed_at < next_date
                    ])
                    weekly_trend.append(day_count)
                
                stats = ChannelStats(
                    channel=channel_type,
                    channel_name=channel_name,
                    total_recipes=total_recipes,
                    today_added=today_added,
                    avg_quality_score=avg_quality,
                    last_processed=last_processed,
                    success_rate=95.0,  # TODO: å®Ÿéš›ã®æˆåŠŸç‡ã‚’è¨ˆç®—
                    weekly_trend=list(reversed(weekly_trend))
                )
                
                stats_list.append(stats)
            
            # ãƒãƒ£ãƒ³ãƒãƒ«ã‚¿ã‚¤ãƒ—é †ã«ã‚½ãƒ¼ãƒˆ
            stats_list.sort(key=lambda s: s.channel.value)
            
            logger.info(f"ğŸ“ˆ Generated channel statistics for {len(stats_list)} channels")
            return stats_list
            
        except Exception as e:
            logger.error(f"Error generating channel statistics: {e}")
            return []
    
    async def invalidate_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡åŠ¹åŒ–"""
        logger.info("ğŸ—‘ï¸ Invalidating recipe cache")
        self._recipe_cache.clear()
        self._cache_last_updated = None
    
    async def get_total_count(self) -> int:
        """ç·ãƒ¬ã‚·ãƒ”æ•°ã‚’å–å¾—"""
        recipes = await self._get_cached_recipes()
        return len(recipes)